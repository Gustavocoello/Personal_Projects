{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn\n",
    "Scikit-learn es una librería de Machine Learning de código abierto que contiene herramientas para pre-procesamiento de datos, entrenamiento y generación de predicciones con diferentes modelos clásicos y selección y validación de modelos, entre otras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Flujo de trabajo en convencional en Scikit-Learn\n",
    "En esencia:\n",
    "\n",
    "- Podemos implementar modelos para tareas de aprendizaje supervisado (como clasificación o regresión) o para aprendizaje NO supervisado (como *clustering*)\n",
    "- En el **pre-procesamiento** generalmente debemos **generar particiones** de los sets de datos (en entrenamiento, validación y prueba) o realizar **transformaciones** de los datos (como el escalamiento)\n",
    "- Luego **creamos una instancia del algoritmo**, **entrenamos** el modelo y lo **validamos** con los sets de entrenamiento, validación y/o prueba\n",
    "- Finalmente, el modelo está listo para **generar predicciones**\n",
    "\n",
    "Veamos de forma práctica los elementos básicos de cada una de estas etapas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pre-procesamiento: generar particiones\n",
    "Una tarea común consiste en dividir el set de datos en los sets de entrenamiento, validación y prueba.\n",
    "\n",
    "Esto lo podemos hacer con la función train_test_split.\n",
    "\n",
    "Para entender cómo usarla comencemos leyendo el set de datos particiones_datos_balanceados.npz (arreglo de NumPy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 3)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "# Datos balanceados \n",
    "X = np.load(\"Data/particiones-datos-balanceados.npz\")['X']\n",
    "Y = np.load('Data/particiones-datos-balanceados.npz')['Y']\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.75275929,  1.11852895, -7.5592353 ],\n",
       "       [ 2.70428584, -3.60506139, -0.0964618 ],\n",
       "       [ 1.39196365, -2.07855351, -9.31222958],\n",
       "       [ 0.59195091, -1.33638157,  8.18640804],\n",
       "       [-2.06388816, -0.43930016, -4.82440037],\n",
       "       [-2.06403288,  2.85175961,  3.25044569],\n",
       "       [-2.65149833, -3.00326218, -3.76577848],\n",
       "       [ 2.19705687,  0.14234438,  0.40136042],\n",
       "       [ 0.60669007,  0.92414569,  0.93420559],\n",
       "       [ 1.24843547, -4.53549587, -6.30291089],\n",
       "       [-2.87649303,  1.07544852,  9.39169256],\n",
       "       [ 2.81945911, -3.29475876,  5.50265647],\n",
       "       [ 1.99465584, -4.34948407,  8.78997883],\n",
       "       [-1.72596534,  4.48885537,  7.89654701],\n",
       "       [-1.9090502 ,  4.65632033,  1.95799958],\n",
       "       [-1.89957294,  3.08397348,  8.4374847 ],\n",
       "       [-1.17454654, -1.95386231, -8.23014996],\n",
       "       [ 0.14853859, -4.02327886, -6.08034275],\n",
       "       [-0.40832989,  1.84233027, -9.09545422],\n",
       "       [-1.25262516, -0.59847506, -3.49339338]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X # Datos en X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y  # Datos en Y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso tenemos un set de datos supervisado, con:\n",
    "\n",
    "- `X`: el arreglo de entrada al modelo (20 datos x 3 características)\n",
    "- `Y`: la variable que deberá aprender a predecir el modelo (20 datos)\n",
    "\n",
    "> **Nota importante:** los arreglos siempre deben estar dimensionados como *n_datos x n_características* (X) y *n_datos* (Y)\n",
    "\n",
    "Supongamos que queremos realizar la partición con estas proporciones:\n",
    "\n",
    "- Entrenamiento: 60%\n",
    "- Validación: 20%\n",
    "- Prueba: 20%\n",
    "\n",
    "En este caso debemos usar `train_test_split` dos veces:\n",
    "\n",
    "- En el primer paso partimos el set de datos en 2: 60% (entrenamiento) y 40% (resto)\n",
    "- En el segundo paso partimos el set de datos restante en 2 mitades: 50% (20% del dataset original, validación) y 50% (20% del dataset original, prueba)\n",
    "\n",
    "Veamos cómo implementar esta partición:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaños\n",
      "\tDataset original:  (20, 3) (20,)\n",
      "\tEntrenamiento:  (12, 3) (12,)\n",
      "\tValidación:  (4, 3) (4,)\n",
      "\tPrueba:  (4, 3) (4,)\n",
      "Proporciones categorías (0s/1s): \n",
      "\tDataset original: 0.55/0.45\n",
      "\tEntrenamiento: 0.5833333333333334/0.4166666666666667\n",
      "\tValidación: 0.5/0.5\n",
      "\tPrueba: 0.5/0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Particion en 60% Train y resto 40% \n",
    "x_train, x_resto, y_train, y_resto = train_test_split(X, Y, test_size=0.4, random_state=123)\n",
    "\n",
    "# Particion \"resto en 2 mitades\" en 20% en validacion y 20% prueba \n",
    "x_val, x_test, y_val, y_test = train_test_split(x_resto, y_resto, test_size=0.5, random_state=321) \n",
    "# Test_size sirve para conocer en como vamos a partir los datos 0.5 es 50%; 0.4 es 60% (train) y 40% (test) \n",
    "# Random_state es semilla de generador aleatorio \n",
    "\n",
    "# Verificamos \n",
    "print(\"Tamaños\")\n",
    "print(\"\\tDataset original: \", X.shape, Y.shape)\n",
    "print('\\tEntrenamiento: ', x_train.shape, y_train.shape)\n",
    "print('\\tValidación: ', x_val.shape, y_val.shape)\n",
    "print('\\tPrueba: ', x_test.shape, y_test.shape)\n",
    "\n",
    "print('Proporciones categorías (0s/1s): ')\n",
    "print(f'\\tDataset original: {np.sum(Y==0)/len(Y)}/{np.sum(Y==1)/len(Y)}')\n",
    "print(f'\\tEntrenamiento: {np.sum(y_train==0)/len(y_train)}/{np.sum(y_train==1)/len(y_train)}')\n",
    "print(f'\\tValidación: {np.sum(y_val==0)/len(y_val)}/{np.sum(y_val==1)/len(y_val)}')\n",
    "print(f'\\tPrueba: {np.sum(y_test==0)/len(y_test)}/{np.sum(y_test==1)/len(y_test)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso anterior lo que hace `train_test_split` es:\n",
    "\n",
    "1. Mezclar aleatoriamente el set de datos\n",
    "2. Generar las particiones con las proporciones correspondientes\n",
    "\n",
    "Es decir, en últimas crea cada subset usando **muestreo aleatorio**.\n",
    "\n",
    "Este muestreo aleatorio es adecuado si por ejemplo estamos implementando un clasificador y las categorías están balanceadas, es decir, tienen más o menos la misma proporción de una categoría o de otra (como es el caso del ejemplo anterior).\n",
    "\n",
    "Sin embargo, este muestreo aleatorio no es adecuado si tenemos datos desbalanceados, es decir con una proporción mayor de una categoría que de otra.\n",
    "\n",
    "Por ejemplo, leamos el dataset `particiones-datos-desbalanceados.npz` y veamos la proporción de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.75275929  1.11852895 -7.5592353 ]\n",
      " [ 2.70428584 -3.60506139 -0.0964618 ]\n",
      " [ 1.39196365 -2.07855351 -9.31222958]\n",
      " [ 0.59195091 -1.33638157  8.18640804]\n",
      " [-2.06388816 -0.43930016 -4.82440037]\n",
      " [-2.06403288  2.85175961  3.25044569]\n",
      " [-2.65149833 -3.00326218 -3.76577848]\n",
      " [ 2.19705687  0.14234438  0.40136042]\n",
      " [ 0.60669007  0.92414569  0.93420559]\n",
      " [ 1.24843547 -4.53549587 -6.30291089]\n",
      " [-2.87649303  1.07544852  9.39169256]\n",
      " [ 2.81945911 -3.29475876  5.50265647]\n",
      " [ 1.99465584 -4.34948407  8.78997883]\n",
      " [-1.72596534  4.48885537  7.89654701]\n",
      " [-1.9090502   4.65632033  1.95799958]\n",
      " [-1.89957294  3.08397348  8.4374847 ]\n",
      " [-1.17454654 -1.95386231 -8.23014996]\n",
      " [ 0.14853859 -4.02327886 -6.08034275]\n",
      " [-0.40832989  1.84233027 -9.09545422]\n",
      " [-1.25262516 -0.59847506 -3.49339338]]\n",
      "[1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Leer datos desbalanceados\n",
    "X = np.load('Data/particiones-datos-desbalanceados.npz')['X']\n",
    "Y = np.load('Data/particiones-datos-desbalanceados.npz')['Y']\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 3)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proporciones categorías (0s/1s) set desbalanceado: \n",
      "\t0.8/0.2\n"
     ]
    }
   ],
   "source": [
    "# Proporción categorías 1 y 0\n",
    "print('Proporciones categorías (0s/1s) set desbalanceado: ')\n",
    "print(f'\\t{np.sum(Y==0)/len(Y)}/{np.sum(Y==1)/len(Y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claramente es un set desbalanceado: 85% categoría \"0\" y 15% categoría \"1\".\n",
    "\n",
    "Así que si hacemos la partición y queremos por ejemplo implementar un modelo de detección de anomalías **debemos preservar estas proporciones**.\n",
    "\n",
    "Esto se logra usando `train_test_split` pero usando un **muestreo estratificado**. En este caso simplemente usamos el argumento `stratify = Y` para que al hacer el muestreo la función tenga en cuenta las proporciones presentes en el arreglo `Y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaños: \n",
      "\tDataset original:  (20, 3) (20,)\n",
      "\tEntrenamiento:  (12, 3) (12,)\n",
      "\tValidación:  (4, 3) (4,)\n",
      "\tPrueba:  (4, 3) (4,)\n",
      "Proporciones categorías (0s/1s): \n",
      "\tDataset original: 0.8/0.2\n",
      "\tEntrenamiento: 0.8333333333333334/0.16666666666666666\n",
      "\tValidación: 0.75/0.25\n",
      "\tPrueba: 0.75/0.25\n"
     ]
    }
   ],
   "source": [
    "# Particion de con muestreo estratificado \n",
    "# Particion 60% (train) y resto (40%)\n",
    "x_train, x_resto, y_train, y_resto = train_test_split(X, Y, test_size=0.4, random_state=20, stratify= Y)\n",
    "#*** MUESTREO ESTRATIFICADO\n",
    "# particion \"resto\" en 2 mitades (Tambien estratficando)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_resto, y_resto, test_size= 0.5, random_state=321, stratify= y_resto)\n",
    "# *** MUESTREO ESTRATIFICADO  \n",
    "\n",
    "# Verificación\n",
    "print('Tamaños: ')\n",
    "print('\\tDataset original: ', X.shape, Y.shape)\n",
    "print('\\tEntrenamiento: ', x_train.shape, y_train.shape)\n",
    "print('\\tValidación: ', x_val.shape, y_val.shape)\n",
    "print('\\tPrueba: ', x_test.shape, y_test.shape)\n",
    "\n",
    "print('Proporciones categorías (0s/1s): ')\n",
    "print(f'\\tDataset original: {np.sum(Y==0)/len(Y)}/{np.sum(Y==1)/len(Y)}')\n",
    "print(f'\\tEntrenamiento: {np.sum(y_train==0)/len(y_train)}/{np.sum(y_train==1)/len(y_train)}')\n",
    "print(f'\\tValidación: {np.sum(y_val==0)/len(y_val)}/{np.sum(y_val==1)/len(y_val)}')\n",
    "print(f'\\tPrueba: {np.sum(y_test==0)/len(y_test)}/{np.sum(y_test==1)/len(y_test)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pre-procesamiento: transformadores\n",
    "\n",
    "> Permiten transformar los datos: escalar (`RobustScaler`, `MinMaxScaler`, `StandardScaler`), codificar (`LabelEncoder`, `OneHotEncoder`) o reducir (`PCA`), entre otras\n",
    "\n",
    "Los pasos para usar un transformador son:\n",
    "\n",
    "1. Crear una instancia del transformador\n",
    "2. Usar el método `fit_transform()` para transformar el set de entrenamiento\n",
    "3. Usar el método `transform()` para transformar los sets de validación y prueba\n",
    "\n",
    "\n",
    "Por ejemplo, veamos los rangos de valores de cada columna en los sets de entrenamiento, validación y prueba (`x_train`, `x_val` y `x_test`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: [-2.87649303 -4.34948407 -9.31222958]/[2.81945911 3.08397348 9.39169256]\n",
      "x_val: [-2.65149833 -3.00326218 -9.09545422]/[2.19705687 1.84233027 0.40136042]\n",
      "x_test: [-1.9090502  -4.53549587 -8.23014996]/[1.24843547 4.65632033 7.89654701]\n"
     ]
    }
   ],
   "source": [
    "print(f'x_train: {x_train.min(axis=0)}/{x_train.max(axis=0)}')\n",
    "print(f'x_val: {x_val.min(axis=0)}/{x_val.max(axis=0)}')\n",
    "print(f'x_test: {x_test.min(axis=0)}/{x_test.max(axis=0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que las variables (columnas) tienen diferentes rangos: -3 a 3, -4 a 5 y -9 a 9 aproximadamente.\n",
    "\n",
    "Así que un tipo de pre-procesamiento sería, por ejemplo, escalar cada columna al mismo rango de valores antes de llevar los datos al modelo.\n",
    "\n",
    "Por ejemplo, supongamos que haremos el escalamiento en el rango de -1 a 1 para lo cual podemos usar el transformador `MinMaxScaler`.\n",
    "\n",
    "Veamos cada uno de los pasos a llevar a cabo. En primer lugar creamos una instancia del transformador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El segundo paso es usar el método `fit_transform()` aplicado sobre el set de entrenamiento (`x_train`). Este método:\n",
    "\n",
    "- Calculará y almacenará en la instancia los mínimos y máximos de cada columna de `x_train`\n",
    "- Y luego escalará `x_train` al rango de -1 a 1 usando los máximos y mínimos recién calculados\n",
    "\n",
    "Veamos este segundo paso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_transform() sobre el set de entrenamiento\n",
    "x_train_s = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mínimos de \"x_train\": [-2.87649303 -4.34948407 -9.31222958]\n",
      "Mínimos calculados por el escalador: [-2.87649303 -4.34948407 -9.31222958]\n",
      "--------------------------------------------------\n",
      "Máximos de \"x_train\": [2.81945911 3.08397348 9.39169256]\n",
      "Máximos calculados por el escalador: [2.81945911 3.08397348 9.39169256]\n"
     ]
    }
   ],
   "source": [
    "print(f'Mínimos de \"x_train\": {x_train.min(axis=0)}')\n",
    "print(f'Mínimos calculados por el escalador: {scaler.data_min_}')\n",
    "print('-'*50)\n",
    "print(f'Máximos de \"x_train\": {x_train.max(axis=0)}')\n",
    "print(f'Máximos calculados por el escalador: {scaler.data_max_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y verifiquemos que `x_train_s` contiene ahora los datos escalados al rango de -1 a 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_s: [-1. -1. -1.]/[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(f'x_train_s: {x_train_s.min(axis=0)}/{x_train_s.max(axis=0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tercer paso es tomar el escalador (scaler) y usar el método transform() para transformar (escalar) los sets de validación (x_val) y prueba (x_test):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_s = scaler.transform(x_val)\n",
    "x_test_s = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifiquemos que ahora el rango de valores en estos dos sets está entre -1 y 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_val_s: [-0.92099839 -0.63779388 -0.97682033]/[0.78145805 0.66593117 0.03866878]\n",
      "x_test_: [-0.66030514 -1.05004718 -0.88429383]/[0.44837189 1.42304589 0.84012492]\n"
     ]
    }
   ],
   "source": [
    "print(f'x_val_s: {x_val_s.min(axis=0)}/{x_val_s.max(axis=0)}')\n",
    "print(f'x_test_: {x_test_s.min(axis=0)}/{x_test_s.max(axis=0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que se realiza el escalamiento pero los valores mínimos y máximos no son exactamente -1 y 1. Esto debido a que el escalamiento se realiza **con base en los valores máximos y mínimos del set de entrenamiento** que no necesariamente son iguales a los de los sets de validación y prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Crear, entrenar y validar el modelo: estimadores\n",
    "\n",
    "En Scikit-Learn los modelos se denominan estimadores.\n",
    "\n",
    "La secuencia de uso es la siguiente:\n",
    "\n",
    "1. Crear una instancia del estimador\n",
    "2. Entrenar el modelo con el set de entrenamiento y el método `fit()`\n",
    "3. Validar el modelo con los sets de entrenamiento y validación usando el método `score()`\n",
    "4. Poner a prueba el modelo con el set de prueba y usando los métodos `predict()` y `score()`\n",
    "\n",
    "Veamos en detalle cada uno de estos pasos. Supongamos que tomaremos el set de datos que hemos venido usando para crear, entrenar, validar y poner a prueba un Bosque Aleatorio.\n",
    "\n",
    "El primer paso es crear una instancia de este estimador (`RandomForestClassifier`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instancia \n",
    "bosque = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El segundo paso es entrenarlo. Para ello usamos el método fit() y le presentamos como argumentos el set de entrenamiento (x_train, y_train):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Entrenamiento\n",
    "bosque.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tercer paso es validar el modelo. Esto quiere decir que la idea es comparar el desempeño con los sets de entrenamiento y validación, para determinar si hay o no *overfitting* u *underfitting*.\n",
    "\n",
    "El desempeño es simplemente una métrica que cuantifica qué tan bien lo esta haciendo el modelo.\n",
    "\n",
    "Verifiquemos en este caso cuál es el desempeño usado por defecto por el bosque aleatorio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ClassifierMixin.score of RandomForestClassifier()>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bosque.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el desempeño se está midiendo con la exactitud promedio (*mean accuracy*).\n",
    "\n",
    "Así que calculemos el desempeño con los sets de entrenamiento y validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud promedio entrenamiento: 1.0\n",
      "Exactitud promedio validación: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(f'Exactitud promedio entrenamiento: {bosque.score(x_train,y_train)}')\n",
    "print(f'Exactitud promedio validación: {bosque.score(x_val, y_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso vemos que el modelo tiene *overfitting*, pues alcanza un 100% de exactitud con el set de entrenamiento y tan sólo un 50% con el set de prueba.\n",
    "\n",
    "En realidad es de esperar pues tenemos poquísimos datos y no hemos modificado ningún parámetro por defecto del modelo.\n",
    "\n",
    "En una situación real deberíamos recolectar más datos y re-entrenar el modelo, posiblemente afinando sus hiperparámetros (pero esto será tema de un tutorial más avanzado).\n",
    "\n",
    "El cuarto y último paso es poner a prueba el modelo. Para ello podemos primero ver el *score* con el set de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bosque.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que sigue siendo del 50% por los mismos motivos mencionados anteriormente.\n",
    "\n",
    "Y, suponiendo que estamos conformes con estos resultados, lo que faltaría sería generar predicciones usando el método `predict()`.\n",
    "\n",
    "Tomemos nuevamente el set de prueba y generemos predicciones con el modelo entrenado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bosque.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y como tenemos tan pocos datos podemos imprimir el comparativo entre las categorías reales (almacenadas en `y_test`) y las categorías predichas (almacenadas en `y_pred`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorías reales:    [0 1 0 0]\n",
      "Categorías predichas: [1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print('Categorías reales:   ', y_test)\n",
    "print('Categorías predichas:', y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y vemos que en efecto de los 4 datos sólo dos (los dos últimos) son clasificados correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. *Pipelines* (tuberías????)\n",
    "\n",
    "Es posible combinar transformadores y estimadores en un sólo objeto: una *pipeline*.\n",
    "\n",
    "Una *pipeline* nos permite hacer lo mismo que con los bloques separados, pero tiene ciertas ventajas:\n",
    "\n",
    "1. El código es más compacto\n",
    "2. Evita lo que se conoce como la fuga de datos (*data leakage*): que los datos de validación sean \"vistos\" por el modelo cuando hacemos el entrenamiento\n",
    "\n",
    "Para hacer un comparativo veamos primero cómo sería el flujo completo de trabajo sin *pipelines*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Flujo de trabajo sin \"pipelines\"\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Leer datos\n",
    "X = np.load('Data/particiones-datos-balanceados.npz')['X']\n",
    "Y = np.load('Data/particiones-datos-balanceados.npz')['Y']\n",
    "\n",
    "# Partición en entrenamiento, validación y prueba\n",
    "x_train, x_resto, y_train, y_resto = train_test_split(\n",
    "    X, Y, test_size=0.4, random_state=123\n",
    ")\n",
    "x_val, x_test, y_val, y_test = train_test_split(\n",
    "    x_resto, y_resto, test_size=0.5, random_state=321\n",
    ")\n",
    "\n",
    "# Escalamiento\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "x_train_s = scaler.fit_transform(x_train)\n",
    "x_val_s = scaler.transform(x_val)\n",
    "x_test_s = scaler.transform(x_test)\n",
    "\n",
    "# Creación, entrenamiento y validación del modelo\n",
    "bosque = RandomForestClassifier()\n",
    "bosque.fit(x_train, y_train)\n",
    "print(bosque.score(x_test,y_test))\n",
    "\n",
    "# Generación de predicciones\n",
    "print(bosque.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "[0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Con pipelines\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Leer datos\n",
    "X = np.load('Data/particiones-datos-balanceados.npz')['X']\n",
    "Y = np.load('Data/particiones-datos-balanceados.npz')['Y']\n",
    "\n",
    "# Partición en entrenamiento, validación y prueba\n",
    "x_train, x_resto, y_train, y_resto = train_test_split(\n",
    "    X, Y, test_size=0.4, random_state=123\n",
    ")\n",
    "x_val, x_test, y_val, y_test = train_test_split(\n",
    "    x_resto, y_resto, test_size=0.5, random_state=321\n",
    ")\n",
    "\n",
    "#------- PIPELINE: SE INTERCONECTAN PREPROCESAMIENTO Y MODELO -------\n",
    "\n",
    "# Instanciar la pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler(feature_range=(-1,1))),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Entrenar la pipeline\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# Evaluar la pipeline\n",
    "print(pipeline.score(x_test, y_test))\n",
    "\n",
    "# Y generar predicciones\n",
    "print(pipeline.predict(x_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
